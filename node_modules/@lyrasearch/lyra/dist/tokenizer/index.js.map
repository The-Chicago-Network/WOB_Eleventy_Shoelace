{"version":3,"sources":["../../src/tokenizer/index.ts"],"sourcesContent":["import { stemmer } from \"@stemmer/en.js\";\nimport { replaceDiacritics } from \"./diacritics.js\";\nimport * as ERRORS from \"../errors.js\";\nimport { Language, SUPPORTED_LANGUAGES } from \"./languages.js\";\nimport { availableStopWords, stopWords } from \"./stop-words/index.js\";\n\nexport * from \"./languages.js\";\n\nexport type Stemmer = (word: string) => string;\n\nexport type TokenizerConfig = {\n  enableStemming?: boolean;\n  enableStopWords?: boolean;\n  customStopWords?: ((stopWords: string[]) => string[]) | string[];\n  stemmingFn?: Stemmer;\n  tokenizerFn?: Tokenizer;\n  assertSupportedLanguage?: (language: string) => void;\n};\n\nexport type TokenizerConfigExec = {\n  enableStemming: boolean;\n  enableStopWords: boolean;\n  customStopWords: string[];\n  stemmingFn?: Stemmer;\n  tokenizerFn: Tokenizer;\n  assertSupportedLanguage: (language: string) => void;\n};\n\nexport type Tokenizer = (\n  text: string,\n  language: Language,\n  allowDuplicates: boolean,\n  tokenizerConfig: TokenizerConfig,\n  frequency?: boolean,\n) => string[];\n\nconst splitRegex: Record<Language, RegExp> = {\n  dutch: /[^A-Za-zàèéìòóù0-9_'-]+/gim,\n  english: /[^A-Za-zàèéìòóù0-9_'-]+/gim,\n  french: /[^a-z0-9äâàéèëêïîöôùüûœç-]+/gim,\n  italian: /[^A-Za-zàèéìòóù0-9_'-]+/gim,\n  norwegian: /[^a-z0-9_æøåÆØÅäÄöÖüÜ]+/gim,\n  portuguese: /[^a-z0-9à-úÀ-Ú]/gim,\n  russian: /[^a-z0-9а-яА-ЯёЁ]+/gim,\n  spanish: /[^a-z0-9A-Zá-úÁ-ÚñÑüÜ]+/gim,\n  swedish: /[^a-z0-9_åÅäÄöÖüÜ-]+/gim,\n  german: /[^a-z0-9A-ZäöüÄÖÜß]+/gim,\n  finnish: /[^a-z0-9äöÄÖ]+/gim,\n  danish: /[^a-z0-9æøåÆØÅ]+/gim,\n  hungarian: /[^a-z0-9áéíóöőúüűÁÉÍÓÖŐÚÜŰ]+/gim,\n  romanian: /[^a-z0-9ăâîșțĂÂÎȘȚ]+/gim,\n  serbian: /[^a-z0-9čćžšđČĆŽŠĐ]+/gim,\n  turkish: /[^a-z0-9çÇğĞıİöÖşŞüÜ]+/gim,\n  lithuanian: /[^a-z0-9ąčęėįšųūžĄČĘĖĮŠŲŪŽ]+/gim,\n  arabic: /[^a-z0-9أ-ي]+/gim,\n  nepali: /[^a-z0-9अ-ह]+/gim,\n  irish: /[^a-z0-9áéíóúÁÉÍÓÚ]+/gim,\n  indian: /[^a-z0-9अ-ह]+/gim,\n  armenian: /[^a-z0-9ա-ֆ]+/gim,\n  greek: /[^a-z0-9α-ωά-ώ]+/gim,\n  indonesian: /[^a-z0-9]+/gim,\n  ukrainian:/[^a-z0-9а-яА-ЯіїєІЇЄ]+/gim,\n  slovenian: /[^a-z0-9čžšČŽŠ]+/gim\n};\n\nexport const normalizationCache = new Map();\n\nfunction normalizeToken(token: string, language: Language, tokenizerConfig: TokenizerConfig): string {\n  const key = `${language}:${token}`;\n\n  if (normalizationCache.has(key)) {\n    return normalizationCache.get(key)!;\n  }\n  // Check if stop-words removal is enabled\n  if (tokenizerConfig?.enableStopWords) {\n    // Remove stop-words\n    if ((tokenizerConfig.customStopWords as string[]).includes(token)) {\n      const token = \"\";\n      normalizationCache.set(key, token);\n      return token;\n    }\n  }\n\n  // Check if stemming is enabled\n  if (tokenizerConfig?.enableStemming) {\n    // Stem token when a stemming function is available\n    if (typeof tokenizerConfig?.stemmingFn === \"function\") {\n      token = tokenizerConfig?.stemmingFn(token);\n    }\n  }\n\n  token = replaceDiacritics(token);\n  normalizationCache.set(key, token);\n  return token;\n}\n\n/* c8 ignore next 10 */\nfunction trim(text: string[]): string[] {\n  while (text[text.length - 1] === \"\") {\n    text.pop();\n  }\n  while (text[0] === \"\") {\n    text.shift();\n  }\n  return text;\n}\n\nfunction assertSupportedLanguage(language: string) {\n  if (!SUPPORTED_LANGUAGES.includes(language)) {\n    throw new Error(ERRORS.LANGUAGE_NOT_SUPPORTED(language));\n  }\n}\n\nexport function tokenize(\n  input: string,\n  language: Language = \"english\",\n  allowDuplicates = false,\n  tokenizerConfig: TokenizerConfig = defaultTokenizerConfig(language),\n) {\n  /* c8 ignore next 3 */\n  if (typeof input !== \"string\") {\n    return [input];\n  }\n\n  const splitRule = splitRegex[language];\n  const tokens = input\n    .toLowerCase()\n    .split(splitRule)\n    .map(token => normalizeToken(token, language, tokenizerConfig!))\n    .filter(Boolean);\n\n  const trimTokens = trim(tokens);\n\n  if (!allowDuplicates) {\n    return Array.from(new Set(trimTokens));\n  }\n\n  return trimTokens;\n}\n\nexport function defaultTokenizerConfig(language: Language, tokenizerConfig: TokenizerConfig = {}): TokenizerConfigExec {\n  let defaultStopWords: string[] = [];\n  let customStopWords: string[] = [];\n  let defaultStemmingFn: Stemmer | undefined;\n  let defaultTokenizerFn: Tokenizer = tokenize;\n\n  // Enable custom tokenizer function\n  if (tokenizerConfig?.tokenizerFn) {\n    if (typeof tokenizerConfig.tokenizerFn !== \"function\") {\n      throw Error(ERRORS.INVALID_TOKENIZER_FUNCTION());\n    }\n    /* c8 ignore next 4 */\n    defaultTokenizerFn = tokenizerConfig.tokenizerFn;\n\n    // If there's no custom tokenizer, we can proceed setting custom\n    // stemming functions and stop-words.\n  } else {\n    // Enable custom stemming function\n    if (tokenizerConfig?.stemmingFn) {\n      if (typeof tokenizerConfig.stemmingFn !== \"function\") {\n        throw Error(ERRORS.INVALID_STEMMER_FUNCTION_TYPE());\n      }\n      defaultStemmingFn = tokenizerConfig.stemmingFn;\n    } else {\n      defaultStemmingFn = stemmer;\n    }\n\n    // Enable default stop-words\n\n    if (availableStopWords.includes(language)) {\n      /* c8 ignore next */\n      defaultStopWords = stopWords[language] ?? [];\n    }\n\n    if (tokenizerConfig?.customStopWords) {\n      switch (typeof tokenizerConfig.customStopWords) {\n        // Execute the custom step-words function.\n        // This will pass the default step-words for a given language as a first parameter.\n        case \"function\":\n          customStopWords = tokenizerConfig.customStopWords(defaultStopWords);\n          break;\n\n        // Check if the custom step-words is an array.\n        // If it's an object, throw an exception. If the array contains any non-string value, throw an exception.\n        case \"object\":\n          if (!Array.isArray(tokenizerConfig.customStopWords)) {\n            throw Error(ERRORS.CUSTOM_STOP_WORDS_MUST_BE_FUNCTION_OR_ARRAY());\n          }\n          customStopWords = tokenizerConfig.customStopWords as string[];\n          if (customStopWords.some(x => typeof x !== \"string\")) {\n            throw Error(ERRORS.CUSTOM_STOP_WORDS_ARRAY_MUST_BE_STRING_ARRAY());\n          }\n          break;\n\n        // By default, throw an exception, as this is a misconfiguration.\n        default:\n          throw Error(ERRORS.CUSTOM_STOP_WORDS_MUST_BE_FUNCTION_OR_ARRAY());\n      }\n    }\n  }\n\n  return {\n    /* c8 ignore next 5 */\n    enableStopWords: tokenizerConfig?.enableStopWords ?? true,\n    enableStemming: tokenizerConfig?.enableStemming ?? true,\n    stemmingFn: defaultStemmingFn,\n    customStopWords: customStopWords ?? defaultStopWords,\n    tokenizerFn: defaultTokenizerFn,\n    assertSupportedLanguage: tokenizerConfig.assertSupportedLanguage ?? assertSupportedLanguage,\n  };\n}\n"],"names":["stemmer","replaceDiacritics","ERRORS","SUPPORTED_LANGUAGES","availableStopWords","stopWords","splitRegex","dutch","english","french","italian","norwegian","portuguese","russian","spanish","swedish","german","finnish","danish","hungarian","romanian","serbian","turkish","lithuanian","arabic","nepali","irish","indian","armenian","greek","indonesian","ukrainian","slovenian","normalizationCache","Map","normalizeToken","token","language","tokenizerConfig","key","has","get","enableStopWords","customStopWords","includes","set","enableStemming","stemmingFn","trim","text","length","pop","shift","assertSupportedLanguage","Error","LANGUAGE_NOT_SUPPORTED","tokenize","input","allowDuplicates","defaultTokenizerConfig","splitRule","tokens","toLowerCase","split","map","filter","Boolean","trimTokens","Array","from","Set","defaultStopWords","defaultStemmingFn","defaultTokenizerFn","tokenizerFn","INVALID_TOKENIZER_FUNCTION","INVALID_STEMMER_FUNCTION_TYPE","isArray","CUSTOM_STOP_WORDS_MUST_BE_FUNCTION_OR_ARRAY","some","x","CUSTOM_STOP_WORDS_ARRAY_MUST_BE_STRING_ARRAY"],"mappings":"AAAA,SAASA,OAAO,QAAQ,mBAAiB;AACzC,SAASC,iBAAiB,QAAQ,kBAAkB;AACpD,YAAYC,YAAY,eAAe;AACvC,SAAmBC,mBAAmB,QAAQ,iBAAiB;AAC/D,SAASC,kBAAkB,EAAEC,SAAS,QAAQ,wBAAwB;AAEtE,cAAc,iBAAiB;AA8B/B,MAAMC,aAAuC;IAC3CC,OAAO;IACPC,SAAS;IACTC,QAAQ;IACRC,SAAS;IACTC,WAAW;IACXC,YAAY;IACZC,SAAS;IACTC,SAAS;IACTC,SAAS;IACTC,QAAQ;IACRC,SAAS;IACTC,QAAQ;IACRC,WAAW;IACXC,UAAU;IACVC,SAAS;IACTC,SAAS;IACTC,YAAY;IACZC,QAAQ;IACRC,QAAQ;IACRC,OAAO;IACPC,QAAQ;IACRC,UAAU;IACVC,OAAO;IACPC,YAAY;IACZC,WAAU;IACVC,WAAW;AACb;AAEA,OAAO,MAAMC,qBAAqB,IAAIC,MAAM;AAE5C,SAASC,eAAeC,KAAa,EAAEC,QAAkB,EAAEC,eAAgC,EAAU;IACnG,MAAMC,MAAM,CAAC,EAAEF,SAAS,CAAC,EAAED,MAAM,CAAC;IAElC,IAAIH,mBAAmBO,GAAG,CAACD,MAAM;QAC/B,OAAON,mBAAmBQ,GAAG,CAACF;IAChC,CAAC;IACD,yCAAyC;IACzC,IAAID,4BAAAA,6BAAAA,KAAAA,IAAAA,gBAAiBI,eAAe,EAAE;QACpC,oBAAoB;QACpB,IAAI,AAACJ,gBAAgBK,eAAe,CAAcC,QAAQ,CAACR,QAAQ;YACjE,MAAMA,QAAQ;YACdH,mBAAmBY,GAAG,CAACN,KAAKH;YAC5B,OAAOA;QACT,CAAC;IACH,CAAC;IAED,+BAA+B;IAC/B,IAAIE,4BAAAA,6BAAAA,KAAAA,IAAAA,gBAAiBQ,cAAc,EAAE;QACnC,mDAAmD;QACnD,IAAI,OAAOR,CAAAA,4BAAAA,6BAAAA,KAAAA,IAAAA,gBAAiBS,UAAU,AAAD,MAAM,YAAY;YACrDX,QAAQE,4BAAAA,6BAAAA,KAAAA,IAAAA,gBAAiBS,UAAU,CAACX;QACtC,CAAC;IACH,CAAC;IAEDA,QAAQnC,kBAAkBmC;IAC1BH,mBAAmBY,GAAG,CAACN,KAAKH;IAC5B,OAAOA;AACT;AAEA,qBAAqB,GACrB,SAASY,KAAKC,IAAc,EAAY;IACtC,MAAOA,IAAI,CAACA,KAAKC,MAAM,GAAG,EAAE,KAAK,GAAI;QACnCD,KAAKE,GAAG;IACV;IACA,MAAOF,IAAI,CAAC,EAAE,KAAK,GAAI;QACrBA,KAAKG,KAAK;IACZ;IACA,OAAOH;AACT;AAEA,SAASI,wBAAwBhB,QAAgB,EAAE;IACjD,IAAI,CAAClC,oBAAoByC,QAAQ,CAACP,WAAW;QAC3C,MAAM,IAAIiB,MAAMpD,OAAOqD,sBAAsB,CAAClB,WAAW;IAC3D,CAAC;AACH;AAEA,OAAO,SAASmB,SACdC,KAAa,EACbpB,WAAqB,SAAS,EAC9BqB,kBAAkB,KAAK,EACvBpB,kBAAmCqB,uBAAuBtB,SAAS,EACnE;IACA,oBAAoB,GACpB,IAAI,OAAOoB,UAAU,UAAU;QAC7B,OAAO;YAACA;SAAM;IAChB,CAAC;IAED,MAAMG,YAAYtD,UAAU,CAAC+B,SAAS;IACtC,MAAMwB,SAASJ,MACZK,WAAW,GACXC,KAAK,CAACH,WACNI,GAAG,CAAC5B,CAAAA,QAASD,eAAeC,OAAOC,UAAUC,kBAC7C2B,MAAM,CAACC;IAEV,MAAMC,aAAanB,KAAKa;IAExB,IAAI,CAACH,iBAAiB;QACpB,OAAOU,MAAMC,IAAI,CAAC,IAAIC,IAAIH;IAC5B,CAAC;IAED,OAAOA;AACT,CAAC;AAED,OAAO,SAASR,uBAAuBtB,QAAkB,EAAEC,kBAAmC,CAAC,CAAC,EAAuB;IACrH,IAAIiC,mBAA6B,EAAE;IACnC,IAAI5B,kBAA4B,EAAE;IAClC,IAAI6B;IACJ,IAAIC,qBAAgCjB;IAEpC,mCAAmC;IACnC,IAAIlB,4BAAAA,6BAAAA,KAAAA,IAAAA,gBAAiBoC,WAAW,EAAE;QAChC,IAAI,OAAOpC,gBAAgBoC,WAAW,KAAK,YAAY;YACrD,MAAMpB,MAAMpD,OAAOyE,0BAA0B,IAAI;QACnD,CAAC;QACD,oBAAoB,GACpBF,qBAAqBnC,gBAAgBoC,WAAW;IAEhD,gEAAgE;IAChE,qCAAqC;IACvC,OAAO;QACL,kCAAkC;QAClC,IAAIpC,4BAAAA,6BAAAA,KAAAA,IAAAA,gBAAiBS,UAAU,EAAE;YAC/B,IAAI,OAAOT,gBAAgBS,UAAU,KAAK,YAAY;gBACpD,MAAMO,MAAMpD,OAAO0E,6BAA6B,IAAI;YACtD,CAAC;YACDJ,oBAAoBlC,gBAAgBS,UAAU;QAChD,OAAO;YACLyB,oBAAoBxE;QACtB,CAAC;QAED,4BAA4B;QAE5B,IAAII,mBAAmBwC,QAAQ,CAACP,WAAW;YACzC,kBAAkB,GAClBkC,mBAAmBlE,SAAS,CAACgC,SAAS,IAAI,EAAE;QAC9C,CAAC;QAED,IAAIC,4BAAAA,6BAAAA,KAAAA,IAAAA,gBAAiBK,eAAe,EAAE;YACpC,OAAQ,OAAOL,gBAAgBK,eAAe;gBAC5C,0CAA0C;gBAC1C,mFAAmF;gBACnF,KAAK;oBACHA,kBAAkBL,gBAAgBK,eAAe,CAAC4B;oBAClD,KAAM;gBAER,8CAA8C;gBAC9C,yGAAyG;gBACzG,KAAK;oBACH,IAAI,CAACH,MAAMS,OAAO,CAACvC,gBAAgBK,eAAe,GAAG;wBACnD,MAAMW,MAAMpD,OAAO4E,2CAA2C,IAAI;oBACpE,CAAC;oBACDnC,kBAAkBL,gBAAgBK,eAAe;oBACjD,IAAIA,gBAAgBoC,IAAI,CAACC,CAAAA,IAAK,OAAOA,MAAM,WAAW;wBACpD,MAAM1B,MAAMpD,OAAO+E,4CAA4C,IAAI;oBACrE,CAAC;oBACD,KAAM;gBAER,iEAAiE;gBACjE;oBACE,MAAM3B,MAAMpD,OAAO4E,2CAA2C,IAAI;YACtE;QACF,CAAC;IACH,CAAC;IAED,OAAO;QACL,oBAAoB,GACpBpC,iBAAiBJ,CAAAA,4BAAAA,6BAAAA,KAAAA,IAAAA,gBAAiBI,eAAe,AAAD,KAAK,IAAI;QACzDI,gBAAgBR,CAAAA,4BAAAA,6BAAAA,KAAAA,IAAAA,gBAAiBQ,cAAc,AAAD,KAAK,IAAI;QACvDC,YAAYyB;QACZ7B,iBAAiBA,mBAAmB4B;QACpCG,aAAaD;QACbpB,yBAAyBf,gBAAgBe,uBAAuB,IAAIA;IACtE;AACF,CAAC"}
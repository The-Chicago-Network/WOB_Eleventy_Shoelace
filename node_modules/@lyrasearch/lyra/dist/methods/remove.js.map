{"version":3,"sources":["../../src/methods/remove.ts"],"sourcesContent":["import type { RadixNode } from \"../trees/radix/node.js\";\nimport type { Lyra, PropertiesSchema, ResolveSchema } from \"../types/index.js\";\nimport { defaultTokenizerConfig } from \"../tokenizer/index.js\";\nimport { removeDocumentByWord } from \"../trees/radix/index.js\";\nimport { flattenObject, getNested } from \"../utils.js\";\nimport { getNodeByKey as getAVLNodeByKey } from \"../trees/avl/index.js\";\nimport * as ERRORS from \"../errors.js\";\nimport { AVLNode } from \"../trees/avl/node.js\";\n\n/**\n * Removes a document from a database.\n * @param lyra The database to remove the document from.\n * @param docID The id of the document to remove.\n * @example\n * const isDeleted = await remove(db, 'L1tpqQxc0c2djrSN2a6TJ');\n */\nexport async function remove<S extends PropertiesSchema>(lyra: Lyra<S>, docID: string): Promise<boolean> {\n  if (!lyra.components?.tokenizer) {\n    lyra.components = {\n      ...(lyra.components ?? {}),\n      tokenizer: defaultTokenizerConfig(lyra.defaultLanguage),\n    };\n  }\n\n  if (!(docID in lyra.docs)) {\n    throw new Error(ERRORS.DOC_ID_DOES_NOT_EXISTS(docID));\n  }\n\n  const document = lyra.docs[docID] || ({} as Record<string, ResolveSchema<S>>);\n  const documentKeys = Object.keys(document || {});\n\n  const documentKeysLength = documentKeys.length;\n  for (let i = 0; i < documentKeysLength; i++) {\n    const key = documentKeys[i];\n\n    const propertyType = lyra.schema[key];\n\n    if (propertyType === \"string\") {\n      const idx = lyra.index[key];\n      const tokens: string[] = lyra.components.tokenizer!.tokenizerFn!(\n        document[key] as string,\n        lyra.defaultLanguage,\n        false,\n        lyra.components.tokenizer!,\n      )!;\n\n      lyra.avgFieldLength[key] = (lyra.avgFieldLength[key] * lyra.docsCount - lyra.fieldLengths[key][docID]) / (lyra.docsCount - 1);\n      delete lyra.fieldLengths[key][docID];\n\n      const tokensLength = tokens.length;\n      for (let k = 0; k < tokensLength; k++) {\n        const token = tokens[k];\n        delete lyra.frequencies[key][docID];\n        lyra.tokenOccurrencies[key][token]--;\n        if (token && !removeDocumentByWord(idx as RadixNode, token, docID)) {\n          throw new Error(ERRORS.CANT_DELETE_DOCUMENT(docID, key, token));\n        }\n      }\n    }\n  }\n\n  removeNumericValue(lyra, docID);\n\n  lyra.docs[docID] = undefined;\n  lyra.docsCount--;\n\n  return true;\n}\n\nfunction removeNumericValue<S extends PropertiesSchema>(lyra: Lyra<S>, docID: string) {\n  const document = lyra.docs[docID] as Record<string, ResolveSchema<S>>;\n  const flatDocument = flattenObject(document);\n  const documentNumericOnly = Object.keys(flatDocument).reduce((acc, key) => {\n    if (getNested(lyra.schema, key) === \"number\") {\n      acc[key] = (flatDocument as any)[key];\n    }\n    return acc;\n  }, {} as Record<string, number>);\n\n  for (const [property, value] of Object.entries(documentNumericOnly)) {\n    const idx = lyra.index[property] as AVLNode<number, string[]>;\n    const node = getAVLNodeByKey(idx, value);\n\n    if (node) {\n      node.value = node.value.filter((id) => id !== docID);\n    }\n  }\n} \n"],"names":["defaultTokenizerConfig","removeDocumentByWord","flattenObject","getNested","getNodeByKey","getAVLNodeByKey","ERRORS","remove","lyra","docID","components","tokenizer","defaultLanguage","docs","Error","DOC_ID_DOES_NOT_EXISTS","document","documentKeys","Object","keys","documentKeysLength","length","i","key","propertyType","schema","idx","index","tokens","tokenizerFn","avgFieldLength","docsCount","fieldLengths","tokensLength","k","token","frequencies","tokenOccurrencies","CANT_DELETE_DOCUMENT","removeNumericValue","undefined","flatDocument","documentNumericOnly","reduce","acc","property","value","entries","node","filter","id"],"mappings":"AAEA,SAASA,sBAAsB,QAAQ,wBAAwB;AAC/D,SAASC,oBAAoB,QAAQ,0BAA0B;AAC/D,SAASC,aAAa,EAAEC,SAAS,QAAQ,cAAc;AACvD,SAASC,gBAAgBC,eAAe,QAAQ,wBAAwB;AACxE,YAAYC,YAAY,eAAe;AAGvC;;;;;;CAMC,GACD,OAAO,eAAeC,OAAmCC,IAAa,EAAEC,KAAa,EAAoB;QAClGD;IAAL,IAAI,CAACA,CAAAA,CAAAA,mBAAAA,KAAKE,UAAU,cAAfF,8BAAAA,KAAAA,IAAAA,iBAAiBG,SAAS,AAAD,GAAG;QAC/BH,KAAKE,UAAU,GAAG;YAChB,GAAIF,KAAKE,UAAU,IAAI,CAAC,CAAC;YACzBC,WAAWX,uBAAuBQ,KAAKI,eAAe;QACxD;IACF,CAAC;IAED,IAAI,CAAEH,CAAAA,SAASD,KAAKK,IAAI,AAAD,GAAI;QACzB,MAAM,IAAIC,MAAMR,OAAOS,sBAAsB,CAACN,QAAQ;IACxD,CAAC;IAED,MAAMO,WAAWR,KAAKK,IAAI,CAACJ,MAAM,IAAK,CAAC;IACvC,MAAMQ,eAAeC,OAAOC,IAAI,CAACH,YAAY,CAAC;IAE9C,MAAMI,qBAAqBH,aAAaI,MAAM;IAC9C,IAAK,IAAIC,IAAI,GAAGA,IAAIF,oBAAoBE,IAAK;QAC3C,MAAMC,MAAMN,YAAY,CAACK,EAAE;QAE3B,MAAME,eAAehB,KAAKiB,MAAM,CAACF,IAAI;QAErC,IAAIC,iBAAiB,UAAU;YAC7B,MAAME,MAAMlB,KAAKmB,KAAK,CAACJ,IAAI;YAC3B,MAAMK,SAAmBpB,KAAKE,UAAU,CAACC,SAAS,CAAEkB,WAAW,CAC7Db,QAAQ,CAACO,IAAI,EACbf,KAAKI,eAAe,EACpB,KAAK,EACLJ,KAAKE,UAAU,CAACC,SAAS;YAG3BH,KAAKsB,cAAc,CAACP,IAAI,GAAG,AAACf,CAAAA,KAAKsB,cAAc,CAACP,IAAI,GAAGf,KAAKuB,SAAS,GAAGvB,KAAKwB,YAAY,CAACT,IAAI,CAACd,MAAM,AAAD,IAAMD,CAAAA,KAAKuB,SAAS,GAAG,CAAA;YAC3H,OAAOvB,KAAKwB,YAAY,CAACT,IAAI,CAACd,MAAM;YAEpC,MAAMwB,eAAeL,OAAOP,MAAM;YAClC,IAAK,IAAIa,IAAI,GAAGA,IAAID,cAAcC,IAAK;gBACrC,MAAMC,QAAQP,MAAM,CAACM,EAAE;gBACvB,OAAO1B,KAAK4B,WAAW,CAACb,IAAI,CAACd,MAAM;gBACnCD,KAAK6B,iBAAiB,CAACd,IAAI,CAACY,MAAM;gBAClC,IAAIA,SAAS,CAAClC,qBAAqByB,KAAkBS,OAAO1B,QAAQ;oBAClE,MAAM,IAAIK,MAAMR,OAAOgC,oBAAoB,CAAC7B,OAAOc,KAAKY,QAAQ;gBAClE,CAAC;YACH;QACF,CAAC;IACH;IAEAI,mBAAmB/B,MAAMC;IAEzBD,KAAKK,IAAI,CAACJ,MAAM,GAAG+B;IACnBhC,KAAKuB,SAAS;IAEd,OAAO,IAAI;AACb,CAAC;AAED,SAASQ,mBAA+C/B,IAAa,EAAEC,KAAa,EAAE;IACpF,MAAMO,WAAWR,KAAKK,IAAI,CAACJ,MAAM;IACjC,MAAMgC,eAAevC,cAAcc;IACnC,MAAM0B,sBAAsBxB,OAAOC,IAAI,CAACsB,cAAcE,MAAM,CAAC,CAACC,KAAKrB,MAAQ;QACzE,IAAIpB,UAAUK,KAAKiB,MAAM,EAAEF,SAAS,UAAU;YAC5CqB,GAAG,CAACrB,IAAI,GAAG,AAACkB,YAAoB,CAAClB,IAAI;QACvC,CAAC;QACD,OAAOqB;IACT,GAAG,CAAC;IAEJ,KAAK,MAAM,CAACC,UAAUC,MAAM,IAAI5B,OAAO6B,OAAO,CAACL,qBAAsB;QACnE,MAAMhB,MAAMlB,KAAKmB,KAAK,CAACkB,SAAS;QAChC,MAAMG,OAAO3C,gBAAgBqB,KAAKoB;QAElC,IAAIE,MAAM;YACRA,KAAKF,KAAK,GAAGE,KAAKF,KAAK,CAACG,MAAM,CAAC,CAACC,KAAOA,OAAOzC;QAChD,CAAC;IACH;AACF"}